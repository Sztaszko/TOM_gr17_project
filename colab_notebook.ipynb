{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colab_notebook",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjjsN7MrnlW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n",
        "! sudo apt-get install git-lfs\n",
        "! git lfs install\n",
        "! git clone https://github.com/neheller/kits19\n",
        "%cd kits19/\n",
        "! python -m starter_code.get_imaging"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lolPyMhSnBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nibabel as nib\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def generate_volume(cid, base_path):\n",
        "  #base_path wskazuje np na content/train\n",
        "  data_path = Path('kits19/data')\n",
        "\n",
        "  case_id = \"case_{:05d}\".format(cid)\n",
        "  case_path = data_path / case_id\n",
        "  vol = nib.load(str(case_path / \"imaging.nii.gz\"))\n",
        "\n",
        "  vol = vol.get_fdata()\n",
        "\n",
        "  check_dir(base_path)\n",
        "\n",
        "  out_path = base_path / \"vol\"\n",
        "  check_dir(out_path)\n",
        "\n",
        "  for i in range(vol.shape[0]):\n",
        "    fpath = out_path / (str(cid)+\"_{:05d}.png\".format(i))\n",
        "    case_im = str(cid)+\"_{:05d}.png\".format(i)\n",
        "    if case_im in os.listdir(out_path):\n",
        "      print(\"picture already saved: \", case_im)\n",
        "    else:\n",
        "      plt.imsave(str(fpath), vol[i], cmap = 'gray')\n",
        "\n",
        "\n",
        "def generate_segm(cid, base_path):\n",
        "  #base_path wskazuje np na content/train\n",
        "  data_path = Path('kits19/data')\n",
        "\n",
        "  case_id = \"case_{:05d}\".format(cid)\n",
        "  case_path = data_path / case_id\n",
        "  segm = nib.load(str(case_path / \"segmentation.nii.gz\"))\n",
        "\n",
        "  segm = segm.get_fdata()\n",
        "\n",
        "  check_dir(base_path)\n",
        "\n",
        "  out_path = base_path / \"segm\"\n",
        "  check_dir(out_path)\n",
        "\n",
        "  for i in range(segm.shape[0]):\n",
        "    fpath = out_path / (str(cid)+\"_{:05d}.png\".format(i))\n",
        "    case_im = str(cid)+\"_{:05d}.png\".format(i)\n",
        "    if case_im in os.listdir(out_path):\n",
        "      print(\"picture already saved: \", case_im)\n",
        "    else:\n",
        "      plt.imsave(str(fpath), segm[i], cmap = 'gray')\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E95XGHLiTMTT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "852ff144-7669-41fa-c80f-18bf32bca57b"
      },
      "source": [
        "%cd /content/\n",
        "#zbior treningowy\n",
        "from pathlib import Path\n",
        "from preprocessing4 import check_dir\n",
        "train_vol_path=Path('/content/train_vol')\n",
        "check_dir(train_vol_path)\n",
        "train_segm_path=Path('/content/train_segm')\n",
        "check_dir(train_segm_path)\n",
        "#zbior walidacyjny\n",
        "val_vol_path=Path('/content/val_vol')\n",
        "check_dir(val_vol_path)\n",
        "val_segm_path=Path('/content/val_segm')\n",
        "check_dir(val_segm_path)\n",
        "#zbior testowy\n",
        "test_vol_path=Path('/content/test_vol')\n",
        "check_dir(test_vol_path)\n",
        "test_segm_path=Path('/content/test_segm')\n",
        "check_dir(test_segm_path)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiTYVa1RTPg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "%cd /content/\n",
        "#definiowanie zbiorow\n",
        "TRAIN_CASES=30\n",
        "VAL_CASES=15   #validation\n",
        "TEST_CASES=10\n",
        "\n",
        "for i in range(TRAIN_CASES):\n",
        "  generate_volume(i,train_vol_path)\n",
        "  generate_segm(i,train_segm_path)\n",
        "\n",
        "\n",
        "for i in range(VAL_CASES):\n",
        "  generate_volume(TRAIN_CASES+i, val_vol_path)\n",
        "  generate_segm(TRAIN_CASES+i,val_segm_path)\n",
        "\n",
        "\n",
        "for i in range(TEST_CASES):\n",
        "  generate_volume(TRAIN_CASES+VAL_CASES+i, test_vol_path)\n",
        "  generate_segm(TRAIN_CASES+VAL_CASES+i, test_segm_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWkKZOP6TUa5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#preprocessing zbior√≥w \n",
        "from preprocessing4 import preprocess_vol, preprocess_segm\n",
        "train_X=preprocess_vol(train_vol_path)\n",
        "train_Y=preprocess_segm(train_segm_path)\n",
        "\n",
        "val_X=preprocess_vol(val_vol_path)\n",
        "val_Y=preprocess_segm(val_segm_path)\n",
        "\n",
        "test_X=preprocess_vol(test_vol_path)\n",
        "test_Y=preprocess_segm(test_segm_path)\n",
        "\n",
        "nb_train_samples=len(train_X.filenames)\n",
        "nb_validation_samples=len(val_X.filenames)\n",
        "nb_test_samples=len(test_X.filenames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELV9zgaIT6b6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import backend as K\n",
        "import keras\n",
        "from unet3 import *\n",
        "import tensorflow as tf\n",
        "\n",
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "IMG_WIDTH=128\n",
        "IMG_HEIGHT=128\n",
        "IMG_CHANNELS=3\n",
        "\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    smooth=1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_coef_multilabel(y_true, y_pred, numLabels=3):\n",
        "    dice=0\n",
        "    for index in range(numLabels):\n",
        "        dice -= dice_coef(y_true[:,:,:,index], y_pred[:,:,:,index])\n",
        "    return dice\n",
        "\n",
        "def multilabel_dice_loss(y_true, y_pred):\n",
        "    return 1-dice_coef_multilabel(y_true, y_pred)\n",
        "\n",
        "# combine generators into one which yields image and masks\n",
        "train_set = zip(train_X,train_Y)\n",
        "val_set = zip(val_X, val_Y)\n",
        "\n",
        "#%% Training model\n",
        "\n",
        "inputs = tf.keras.layers.Input((IMG_WIDTH,IMG_HEIGHT,IMG_CHANNELS))\n",
        "outputs = build_unet(inputs)\n",
        "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "model.compile(optimizer= 'adam', loss=multilabel_dice_loss,\n",
        "              metrics=[dice_coef_multilabel])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "batch_size=128\n",
        "epochs=5\n",
        "\n",
        "model.fit_generator(\n",
        "    train_set,\n",
        "    steps_per_epoch=nb_train_samples / batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_set,\n",
        "    validation_steps=nb_validation_samples / batch_size,\n",
        "    callbacks=callbacks)\n",
        "\n",
        "model.save('Model_save')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAt2N2Tu3635",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(model.history.history['loss'])\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkAKHicy98-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred=model.predict_generator(test_X)"
      ],
      "execution_count": 41,
      "outputs": []
    }
  ]
}